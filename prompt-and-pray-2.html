<!DOCTYPE html><html lang="sv"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Från dumma chatbotar till AI-agenter - Voz Máquina</title><meta name="description" content="En inblick i hur konversationsdesign har förändrats i takt med språkmodellernas framväxt."><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="./prompt-and-pray-2.html"><link rel="shortcut icon" href="./media/website/favicon.ico" type="image/x-icon"><link rel="preload" href="./assets/dynamic/fonts/adventpro/adventpro.woff2" as="font" type="font/woff2" crossorigin><link rel="stylesheet" href="./assets/css/style.css?v=4fff08add8af6f10f1133005eebd9b7a"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"./prompt-and-pray-2.html"},"headline":"Från dumma chatbotar till AI-agenter","datePublished":"2025-03-04T23:28+01:00","dateModified":"2025-06-20T23:16+02:00","description":"En inblick i hur konversationsdesign har förändrats i takt med språkmodellernas framväxt.","author":{"@type":"Person","name":"Oscar","url":"./authors/oscar/"},"publisher":{"@type":"Organization","name":"Oscar"}}</script><noscript><style>img[loading] {
                    opacity: 1;
                }</style></noscript><script defer="defer" src="https://cloud.umami.is/script.js" data-website-id="cd804dda-e4b3-4550-ad8a-731c84896c7d"></script></head><body class="post-template"><div class="container container--nosidebar"><div class="left-bar"><div class="left-bar__inner"><header class="header"><a class="logo" href="./">Voz Máquina </a><a class="logo logo--atbottom" href="./">Voz Máquina</a></header></div></div><main class="main post"><article class="content"><div class="main__inner"><div class="content__meta"><div class="content__author"><div><a href="./authors/oscar/" class="content__author__name">Oscar</a></div></div><div class="content__date"><time datetime="2025-03-04T23:28">mar 4, 2025</time></div></div><header class="content__header"><h1 class="content__title">Från dumma chatbotar till AI-agenter</h1></header><div class="content__entry"><p>Ett uttryck som börjat cirkulera i samband med generativ AI är <strong><em>prompt and pray</em></strong>. Det är ett uttryck för att beskriva språkmodellernas oförutsägbarhet i situationer där man vill att de agerar konsekvent. Detta är som många redan förklarat ett inneboende beteende, och för att citera Karpathy <em><strong>"a feature, not a bug"</strong></em>.</p><p>I praktiken innebär detta att arbetet med språkmodeller – särskilt vid promptskrivning – ofta handlar mindre om att specificera <i>vad</i> modellen ska göra, och mer om att avgränsa <i>vad</i> den inte ska göra. Det görs paradoxalt nog genom att just precis fokusera på önskat beteende. Genom att lägga till kontext, sätta upp <i>guardrails</i> och formulera promptar som tydligt ramar in uppgiften, styr man modellen bort från oönskade tolkningar och mot ett mer förutsägbart resultat.</p><p>En applikation, eller chatbot, som levererar opålitlig eller hallucinerad information kan skapa fler problem än den löser. Men det har inte alltid varit så här. För några år sedan var det faktiskt tvärtom. Chatbotar hade 0% hallucinationer, men de var däremot trögare, dummare och kunde inte hantera naturligt språk.</p><p><strong>Från gamla NLU-modeller till dagens språkmodeller</strong></p><p data-pm-slice="1 1 []">Tidigare byggdes chatbotar ofta med så kallade NLU-modeller (Natural Language Understanding). Dessa modeller krävde att vi manuellt definierade specifika intentioner och träningsfraser för att systemet skulle kunna förstå användarens frågor. De var förutsägbara och pålitliga – hade modellen tränats för en viss fråga gav den konsekvent samma svar.</p><p>Den stora svagheten låg dock i deras oförmåga att hantera konversationer på samma sätt som människor. De fungerade utmärkt inom smala, tydligt avgränsade områden med lätta frågor att förutse. Men när användare ställde en oväntad fråga – något utanför träningsområdet – gavs ofta det frustrerande svaret: ”Tyvärr, jag har inget svar på din fråga.” Problemet var just att mänsklig kommunikation ofta är oförutsägbar på det sättet.</p><p>Jag brukar beskriva NLU-modeller som ett korthus – snyggt och noggrant uppbyggt för ett specifikt syfte, men så fort det kom en oväntad formulering eller fråga rasade allt samman.</p><p>Jag minns tydligt när jag arbetade med en stor NLU-modell för telefonsamtal. Modellen hade ungefär 200 olika intents med 5–10 träningsfraser vardera, förstärkta med entiteter. Men eftersom <em>naturligt språk</em> är komplext, varierat och ibland ostrukturerat var det ofta modellen misslyckades med att korrekt tolka användarens avsikt. Efter att ha lagt över 200 timmar på träning, tester och förbättringar var detta oerhört frustrerande.</p><h3 data-pm-slice="1 1 []">Den nya generationen språkmodeller</h3><p>Dagens språkmodeller erbjuder en helt annan verklighet. De kan direkt förstå och generera språk med en häpnadsväckande flexibilitet – helt utan att kräva manuellt skrivna intentioner eller träningsfraser. Varje ny modell sedan 2022 har varit ännu mer imponerande.</p><p>För dem som först mötte den här tekniken var upplevelsen nästan magisk, och uppfattad som överlägsen intelligens. För språkteknologer, conversation designers och utvecklare som länge arbetat med människa-till-dator-kommunikation var det inget mindre än en revolution – ett kraftfullt verktyg med enorm potential. Men med den ökade kapaciteten följde också en ny utmaning: kontroll över vad modellen faktiskt säger.</p><p>Det förvånar mig därför inte att det råder delade meningar om språkmodeller och AI. För mig, och många andra med ambitionen att kunna prata naturligt med maskiner, är detta ett otroligt spännande område att verka inom. Varje experiment tar oss ett steg närmare en framtid där konversationen med AI känns helt naturlig. Men det är viktigt att minnas att språkmodeller i sig inte ”vet” någonting. Kunskapen finns i systemen omkring – databaser, grafer och andra informationskällor. Språkmodellerna agerar istället som ett gränssnitt för att kommunicera med denna information.</p><h3 data-pm-slice="1 1 []">Från att övertyga till att hantera förväntningar</h3><p>Arbetet som conversation designer eller utvecklare har alltså skiftat perspektiv. Tidigare handlade det ofta om att övertyga människor om att chatbotar faktiskt kunde bidra med något värdefullt, trots deras brister. Idag handlar det snarare om att hantera förväntningar och tydligt kommunicera vad generativ AI faktiskt kan och inte kan göra.</p><p>Språkmodeller har en imponerande förmåga att förstå naturligt språk, men deras svaghet att generera trovärdiga svar. Detta leder till missförstånd och hallucinationer, vilket skapar frustration hos användarna. Vi människor är vana att tolka subtila sociala signaler i språket – som säkerhet, intelligens och kunskap. När vi omedvetet försöker läsa av dessa signaler när vi kommunicerar med en språkmodell uppstår ofta felbedömningar.</p><p data-pm-slice="1 1 []">Mycket av mitt arbete idag handlar därför om att hålla språkmodeller i schack och säkerställa att deras svar är trovärdiga och korrekta. Detta har gett mig en hel del kunskap och insikt om hur olika åtgärder och tekniker faktiskt påverkar resultaten.</p><p>På senare tid har AI-agenter lyfts fram som nästa stora genombrott. Tidigt såg vi exempelvis Perplexity, och nyligen har så kallade "Deep Research-agenter”, som både OpenAI och Google lanserat, börjat få mycket uppmärksamhet.</p><p>I praktiken handlar det helt enkelt om en annan typ av arkitektur där språkmodeller "jobbar tillsammans". Det är särskilt intressant eftersom just arkitektur var avgörande när vi byggde agenter baserade på NLU-modeller.</p><p>De kvalitativa skillnaderna i svar är betydande och ofta imponerande i agent-system, men nackdelen är oftast högre kostnader och längre svarstider per svar.</p><h3 data-pm-slice="1 1 []">Är AI-agenterna framtiden?</h3><p>Frågan många ställer sig är: Hur mycket är ren hype, och hur mycket verklig nytta levererar dessa AI-agenter egentligen?</p><p>Mycket pekar idag på att de senaste framstegen inom AI-agenters arkitektur har potential att revolutionera många branscher. Men utvecklingen kommer sannolikt att ske ganska ojämnt – vissa områden kommer snabbt att integrera AI-agenter medan andra kommer att ta längre tid på sig.</p><p>Det finns en mängd rapporter som både bekräftar och nyanserar hur stor påverkan AI-agenter kan komma att ha inom olika områden. Många av dessa rapporter är mycket optimistiska – inte sällan från aktörer som själva utvecklar språkmodeller.</p><p>Inom en snar framtid kommer kanske begreppet ”AI-agenter” gå från att vara ett buzzword till att bli helt normaliserat. Eller så försvinner själva ordet, men produkterna bakom det blir normaliserade.</p><p>Precis som med andra typer av verktyg kommer specialiserade lösningar vara att föredra framför generella lösningar. Språkmodeller är kraftfulla, men bara en del av helheten – ett verktyg måste alltid väljas och anpassas efter användningsområde. Precis som man idag väljer ett specialiserat CRM-verktyg istället för att använda Excel som CRM-system, kommer vi troligtvis välja specialiserade AI-agenter och AI-verktyg anpassade efter våra behov.</p><p>Denna specialisering öppnar upp för en marknad där nischade AI-agenter, skräddarsydda efter specifika branschers behov, blir avgörande. De mer allmäna och generella AI-agenterna kommer sannolikt ha svårt att tävla med dessa på sikt.</p><p>På lång sikt är det viktigt att förstå att AI-agenter (eller vad vi nu väljer att kalla dem) sannolikt inte kommer att ”rädda” oss över en natt. Istället kommer de gradvis att bli en naturlig del av vår verktygslåda – något vi lär oss använda, förbättra och integrera i vardagliga arbetsflöden.</p><p>Precis som med tidigare teknikskiften kommer vi att möta både tydliga begränsningar och möjligheter. Genom att fortsätta utforska, experimentera och utmana tekniken tar vi oss stegvis framåt och lär oss mer om var tekniken gör störst nytta.</p></div><footer class="content__footer"><div class="content__last-updated">This article was updated on <time datetime="2025-06-20T23:16">jun 20, 2025</time></div><div class="content__share"><a href="https://www.linkedin.com/sharing/share-offsite/?url=%23PUBLII_RELATIVE_URL_BASE%23%2Fprompt-and-pray-2.html" class="js-share linkedin tltp tltp--top" aria-label="Share with LinkedIn" rel="nofollow noopener noreferrer"><svg><use xlink:href="./assets/svg/svg-map.svg#linkedin"/></svg> <span>LinkedIn</span></a></div></footer></div></article><div class="content__section post__related"><div class="main__inner"><h3 class="content__section__title">Related post</h3><div class="post__related__wrap"><article class="c-card"><div class="c-card__meta"><div class="c-card__author"><a href="./authors/oscar/">Oscar</a></div><time datetime="2025-01-30T21:54">jan 30, 2025</time></div><header class="c-card__header"><h2 class="c-card__title"><a href="./kan-ai-agenter-driva-ett-foretag.html">Kan AI-agenter driva ett företag?</a></h2><p>TLDR – för den som inte orkar läsa allt I en ny&hellip;</p></header></article></div></div></div></main></div><script defer="defer" src="./assets/js/scripts.min.js?v=b2d91bcadbf5db401b76eb5bb3092eb7"></script><script>var images = document.querySelectorAll('img[loading]');
        for (var i = 0; i < images.length; i++) {
            if (images[i].complete) {
                images[i].classList.add('is-loaded');
            } else {
                images[i].addEventListener('load', function () {
                    this.classList.add('is-loaded');
                }, false);
            }
        }</script></body></html>